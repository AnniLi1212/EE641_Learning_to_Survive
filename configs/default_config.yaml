environment:
  name: "survival_game"
  render_mode: "human"
  max_steps: 1000 # max steps per episode
  size: 16 # grid size
  num_food: 10
  num_threats: 5
  food_value_min: 10
  food_value_max: 30
  threat_attack_min: 20
  threat_attack_max: 40
  agent_attack_min: 25
  agent_attack_max: 45
  hungry_decay: 4
  observation_range: 4
  threat_perception_range: 3
  num_caves: 5
  cave_health_recovery: 2
  hungry_health_penalty: 3

agent:
  type: "dqn" # "dqn", "random"
  memory_size: 100000 # replay buffer size
  batch_size: 128
  gamma: 0.99
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay: 0.997
  learning_rate: 0.00003
  target_update: 10 # update target network every x episodes
  hidden_sizes: [512, 256, 128]

training:
  max_episodes: 500
  eval_frequency: 10
  eval_episodes: 50 # num of episodes for eval
  save_frequency: 10
  patience: 50 # early stopping
  checkpoint_dir: "results/checkpoints"
  log_dir: "results/logs"

evaluation:
  num_episodes: 50
  render: true
  save_dir: "results/evaluation"