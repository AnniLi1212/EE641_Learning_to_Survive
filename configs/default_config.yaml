environment:
  name: "survival_game"
  render_mode: "human"
  max_steps: 100 # max steps per episode
  size: 16 # grid size
  num_food: 10
  num_threats: 5
  food_value_min: 10
  food_value_max: 30
  threat_attack_min: 20
  threat_attack_max: 40
  agent_attack_min: 30
  agent_attack_max: 50
  hungry_decay: 2
  observation_range: 4
  threat_perception_range: 2
  num_caves: 2
  cave_health_recovery: 8

agent:
  type: "dqn" # "dqn", "random"
  memory_size: 100000 # replay buffer size
  batch_size: 128
  gamma: 0.99
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay: 0.997
  learning_rate: 0.0003
  target_update: 10 # update target network every x episodes
  hidden_sizes: [256, 128]

training:
  max_episodes: 100
  num_episodes: 100
  eval_frequency: 10
  eval_episodes: 10 # num of episodes for eval
  save_frequency: 10
  log_frequency: 1
  patience: 50 # early stopping
  checkpoint_dir: "results/checkpoints"
  log_dir: "results/logs"

evaluation:
  num_episodes: 10
  render: true
  save_video: false